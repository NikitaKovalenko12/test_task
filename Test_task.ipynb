{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 1. Программирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, -1, 2, 1]\n",
      "sum: 6\n"
     ]
    }
   ],
   "source": [
    "array = [-2, 1, -3, 4, -1, 2, 1, -5, 4]\n",
    "\n",
    "def max_sum_subarray(arr):\n",
    "    n = len(arr)\n",
    "\n",
    "    max_end = min(arr) - 1\n",
    "      \n",
    "    max_so_far = min(arr) - 1\n",
    "      \n",
    "    for i in range(n): \n",
    "        if (max_end < 0):\n",
    "            max_end = arr[i]\n",
    "            a=i\n",
    "            \n",
    "        else: \n",
    "            max_end += arr[i] \n",
    "            b=i-1\n",
    "        max_so_far = max(max_so_far, max_end) \n",
    "    \n",
    "    print(arr[a:b])\n",
    "    return print('sum:', max_so_far)\n",
    "\n",
    "max_sum_subarray(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2. ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Установим библиотеку с нашей предобученной нейронной сетью:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install git+https://github.com/nizhib/pytorch-insightface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим выборки, создав директории для обучающей, валидационной и тестовой выборки. В них будут папки с классами, затем полный датасет распределим по этим папкам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil \n",
    "from tqdm import tqdm\n",
    "\n",
    "train_dir = 'train'\n",
    "val_dir = 'val'\n",
    "test_dir = 'test'\n",
    "\n",
    "class_names = ['female', 'male']\n",
    "\n",
    "for dir_name in [train_dir, val_dir, test_dir]:\n",
    "    for class_name in class_names:\n",
    "        os.makedirs(os.path.join(dir_name, class_name), exist_ok=True)\n",
    "\n",
    "for class_name in class_names:\n",
    "    source_dir = os.path.join('internship_data', class_name)\n",
    "    for i, file_name in enumerate(tqdm(os.listdir(source_dir))):\n",
    "        if i % 5 == 1:\n",
    "            dest_dir = os.path.join(test_dir, class_name)\n",
    "        elif i % 5 == 0:\n",
    "            dest_dir = os.path.join(val_dir, class_name)   \n",
    "        else:\n",
    "            dest_dir = os.path.join(train_dir, class_name)\n",
    "        shutil.copy(os.path.join(source_dir, file_name), os.path.join(dest_dir, file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Составим датасеты из наших папок с помощью *ImageFolder* и проведем на них трансформации. Для обучающей выборки трансформации будут включать не только изменение размера, преобразование в тензор и нормализацию, но и аугментацию - горизонтальное отзеркаливание. Для остальных выборок все кроме аугментаций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "\n",
    "from torchvision import transforms, models\n",
    "if __name__ == \"__main__\":\n",
    "    mean = [0.5] * 3\n",
    "    std = [0.5 * 256 / 255] * 3\n",
    "\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.Resize((112, 112)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "\n",
    "    valtest_transforms = transforms.Compose([\n",
    "        transforms.Resize((112, 112)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "    train_dataset = torchvision.datasets.ImageFolder(train_dir, train_transforms)\n",
    "    val_dataset = torchvision.datasets.ImageFolder(val_dir, valtest_transforms)\n",
    "    test_dataset = torchvision.datasets.ImageFolder(test_dir, valtest_transforms)\n",
    "\n",
    "    batch_size = 256\n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    val_dataloader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    test_dataloader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим функцию обучения модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, loss, optimizer, scheduler, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}:'.format(epoch, num_epochs - 1), flush=True)\n",
    "\n",
    "        # Каждая эпоха имеет фазу обучения и валидации\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                dataloader = train_dataloader\n",
    "                scheduler.step()\n",
    "                model.train()  # включить режим обучения\n",
    "            else:\n",
    "                dataloader = val_dataloader\n",
    "                model.eval()   # включить режим прохода по сети без ее обучения.\n",
    "\n",
    "            running_loss = 0.\n",
    "            running_acc = 0.\n",
    "\n",
    "            # пройдемся по данным\n",
    "            for inputs, labels in tqdm(dataloader):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward and backward\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    preds = model(inputs)\n",
    "                    loss_value = loss(preds, labels)\n",
    "                    preds_class = preds.argmax(dim=1)\n",
    "\n",
    "                    # обратное распространение ошибки + оптимизация только в фазе обучения\n",
    "                    if phase == 'train':\n",
    "                        loss_value.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # функция потерь и accuracy\n",
    "                running_loss += loss_value.item()\n",
    "                running_acc += (preds_class == labels.data).float().mean()\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloader)\n",
    "            epoch_acc = running_acc / len(dataloader)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc), flush=True)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша модель - IResNet34, она отсюда - https://github.com/deepinsight/insightface, в задании использован ее порт на pytorch: https://github.com/nizhib/pytorch-insightface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import insightface\n",
    "model = insightface.iresnet34(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заморозим веса предобученной сети, изменим выходной слой чтобы он предсказывал вероятности только для двух классов и обозначим наш оптимизационный алгоритм *Adam*. Также обозначим планировщик, который будет уменьшать скорость обучения каждые 7 эпох."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заморозим веса всех сверточных слоев\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Изменим выходной слой и слой батч-нормализации, так как класса у нас всего два.\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 2,bias=True)\n",
    "model.features =  torch.nn.BatchNorm1d(2, eps=2e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
    "\n",
    "# Обучать модель будем с помощью видеокарты.\n",
    "device = torch.device(\"cuda:0\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Функция потерь - кросс-энтропия, метод оптимизации - Adam.\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1.0e-3)\n",
    "\n",
    "# Планировщик уменьшающий LR в 10 раз каждые 7 эпох.\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/13:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nikita\\anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 235/235 [07:15<00:00,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2004 Acc: 0.9587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 79/79 [02:18<00:00,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1624 Acc: 0.9710\n",
      "Epoch 1/13:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 235/235 [07:33<00:00,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1495 Acc: 0.9713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 79/79 [02:23<00:00,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1284 Acc: 0.9719\n",
      "Epoch 2/13:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 235/235 [07:20<00:00,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1262 Acc: 0.9736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 79/79 [02:27<00:00,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1313 Acc: 0.9694\n",
      "Epoch 3/13:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 235/235 [07:24<00:00,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1120 Acc: 0.9745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 79/79 [02:20<00:00,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1006 Acc: 0.9743\n",
      "Epoch 4/13:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 235/235 [07:23<00:00,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1008 Acc: 0.9761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 79/79 [02:21<00:00,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1044 Acc: 0.9746\n",
      "Epoch 5/13:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 235/235 [07:14<00:00,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0934 Acc: 0.9759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 79/79 [02:15<00:00,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1009 Acc: 0.9715\n",
      "Epoch 6/13:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 235/235 [07:03<00:00,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0859 Acc: 0.9786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 79/79 [02:14<00:00,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0922 Acc: 0.9762\n",
      "Epoch 7/13:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 235/235 [07:18<00:00,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0839 Acc: 0.9795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 79/79 [02:22<00:00,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0850 Acc: 0.9752\n",
      "Epoch 8/13:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 235/235 [07:15<00:00,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0838 Acc: 0.9791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 79/79 [02:15<00:00,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0849 Acc: 0.9764\n",
      "Epoch 9/13:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 235/235 [07:06<00:00,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0826 Acc: 0.9791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 79/79 [02:14<00:00,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0826 Acc: 0.9771\n",
      "Epoch 10/13:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 235/235 [07:13<00:00,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0819 Acc: 0.9795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 79/79 [02:17<00:00,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0817 Acc: 0.9764\n",
      "Epoch 11/13:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 235/235 [07:12<00:00,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0806 Acc: 0.9799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 79/79 [02:17<00:00,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0818 Acc: 0.9768\n",
      "Epoch 12/13:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 235/235 [07:09<00:00,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0798 Acc: 0.9795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 79/79 [02:15<00:00,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0832 Acc: 0.9771\n",
      "Epoch 13/13:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 235/235 [07:10<00:00,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0779 Acc: 0.9806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 79/79 [02:15<00:00,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0844 Acc: 0.9768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model, loss, optimizer, scheduler, num_epochs=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим предсказания на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 79/79 [02:21<00:00,  1.79s/it]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "test_predictions = []\n",
    "test_img_paths = []\n",
    "for inputs, labels in tqdm(test_dataloader):\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    with torch.set_grad_enabled(False):\n",
    "        preds = model(inputs)\n",
    "    test_predictions.append(\n",
    "        torch.nn.functional.softmax(preds, dim=1)[:,1].data.cpu().numpy())\n",
    "    \n",
    "test_predictions = np.concatenate(test_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим accuracy на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97755"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_dataset.targets,(test_predictions>0.5).astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'internship_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
